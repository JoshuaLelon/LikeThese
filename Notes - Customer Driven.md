## Step 1: come up with a [type of customer]

- tips: getting the [type of customers] parameter right
    
    Defining the customer: characteristics (age, experience, skills, etc), context/environment, current behaviors, motivations
    
    *When we formulate our Customer hypothesis, we want to be sure that*
    *the [type of customers] parameter isn’t defined by the customer’s problem,*
    *the task they’re doing, or the product they’re using. This parameter*
    *should reflect the customer’s identity.*
    
    *In their book Lean Enterprise, authors Jez Humble, Joanne Molesky,*
    *and Barry O’Reilly suggest the most effective way to segment customers*
    *is to “pinpoint a cause and effect relationship between a person’s*
    *characteristics and his or her interest in in your offering.”*
    
    *In other words, you want to identify unique attributes of customers who are or are not interested in your products.*
    
    *Cindy Alvarez says that you should not become overreliant on traditional*
    *labels, like marketing demographics.6 Age, gender, ethnicity,*
    *and location are important, but these attributes do not completely*
    *define your customer.*
    
    *Identifying motivations, interests, unique perspectives, and behaviors*
    *is much more powerful and insightful than a list of generic demographic*
    *information. Therefore, being specific about the type of customer*
    *will lead to greater clarity when you’re making sense of the*
    *data you’ve collected and sharing what you’ve learned.*
    
    - Example
        
        *Imagine we’re members of a team working on a desktop publishing*
        *tool. Our tool, called StarDoc, allows customers to create flyers, newsletters,*
        *calendars, and business documents like memos and letters.*
        *Our team is looking for new opportunities to help small businesses*
        *with document creation.*
        
        *When creating Customer hypotheses, we want to make sure that we’re*
        *separating the customer from the product.*
        
        *For example, we shouldn’t begin our Customer hypothesis by saying:*
        
        - *We believe StarDoc users are motivated to [motivation] when*
        *doing [job-to-be-done].*
        
        *We would say:*
        
        - *We believe office administrators working for small businesses are motivated to [motivation] when doing [job-to-be-done].*
    
    *Effectively, the customer has an identity beyond the fact that they use*
    *StarDoc. It’s important to capture that identity so we know, specifically,*
    *whom we’re talking about when we refer to this segment of our*
    *customer base.*
    
- brainstorming prompts for [type of customers]
    - *We are targeting [type of customers].*
    - *These [type of customers] work in teams/organizations that*
    *are .*
    - *These [type of customers] are skilled in .*
    - *These [type of customers] are at stage of their*
    *career.*
    - *These [type of customers] have job title.*
    - *These [type of customers] are building types of*
    *products, applications, or services.*
    - *These [type of customers] are experiencing the following*
    *market pressures: .*
    - *These [type of customers] use the following tools, platforms,*
    *and technologies to achieve their goals: .*

## Step 2: come up with a [motivation]

- tips: getting the [motivation] right
    
    *Let’s go back to our example of office administrators working for small*
    *businesses. We think that these administrators have a strong desire*
    *to create promotional brochures for their businesses. We might be*
    *inclined to continue our Customer hypothesis by saying:*
    
    - *We believe office administrators working for small businesses*
    *are motivated to make a promotional brochure when doing*
    *[job-to-be-done].*
    
    *However, when you look at this hypothesis, it feels like it’s missing*
    *a higher-level motivation. Sure, the customer’s goal is to make a promotional*
    *brochure, but the first questions that come to mind are, “Why do they want to create a brochure? What are they hoping it will accomplish?”*
    
    *After talking with office administrators about their desire to create*
    *brochures, we learn that many of them are struggling to find low-cost*
    *ways to promote their business offerings. So, we revise our Customer*
    *hypothesis to capture that motivation:*
    
    - *We believe office administrators working for small businesses*
    *are motivated to promote their business offerings when doing*
    *[job-to-be-done].*
    
    *By capturing the higher-level motivation, we’ve opened our hypothesis*
    *up to many more opportunities. This will help us explore various jobs*
    *our office administrators will “hire,” using our product, to advance*
    *their goal of promoting their business.*
    
- brainstorming prompts for [motivation]
    - *these customers are motivated by .*
    - *These customers are influenced by .*

## Step 3: come up with a [job-to-be-done]

- tips: getting the [job-to-be-done] right
    
    *So, let’s try to plug StarDoc into our job-to-be-done, within our*
    *Customer hypothesis:*
    
    - *We believe office administrators working for small businesses are*
    *motivated to promote their business offerings when using StarDoc.*
    
    *You may have noticed we’ve changed the verb from doing to using.*
    *From time to time, you’ll find that you need to change the HPF templates*
    *to make them easier to read or understand. Again, these templates*
    *should serve only as an example. You’re free to rework them*
    *however you’d like; it’s the hypothesis parameters we strongly encourage*
    *you to keep.*
    
    *The job-to-be-done in this hypothesis focuses on the product (StarDoc)*
    *rather than the task (creating a promotional brochure). Therefore, we*
    *want to articulate what job the customer is “hiring” to promote their*
    *business offering. In this case, we believe the customer has chosen a*
    *brochure to achieve their goal:*
    
    - *We believe office administrators working for small businesses are*
    *motivated to promote their business offerings when creating promotional*
    *brochures.*
    
    *This completed Customer hypothesis sheds light on the type of customer,*
    *their motivation, and the job they’re engaged in. We could now*
    *run an experiment on this hypothesis by talking with office administrators*
    *about how they promote their businesses. We could then determine*
    *if they engage in activities like creating brochures.*
    
    *We could have several variants of this hypothesis with different job-tobe-*
    *done parameters, such as creating posters, creating flyers, or creating*
    *newsletters. These variants could happen with any one of the*
    *Customer parameters.*
    
    - Job-to-be-done: *For example, a customer doesn’t want a drill, they want a quarter-inch*
    *hole. Therefore, they “hire” a drill to achieve that for them*
- brainstorming prompts for [job-to-be-done]
    - *These customers are focused on doing [job-to-be-done].*
    - *We want to help customers achieve .*
    - *When customers engage in [job-to-be-done], they’re doing*
    *the following tasks: .*
    - *When engaged in [job-to-be-done], these customers often*
    *enlist the help of .*

## Step 4: come up with a [problem]

- tips: getting the [problem] right
    - *The Problem stage introduces the [problem] parameter, which essentially is the problem or limitation you believe exists for the customer when they engage in the [job-to-be-done]. At its heart, the Problem stage is where we focus on what’s preventing the customers from achieving their goals. While we may have technical limitations within our product, there can also be many external factors that prevent our customers from achieving a desirable outcome.*
    - Problems are patterns of need or opportunity, process breakdowns, common ways customers are solving a problem, feelings, emotions
    - focus on the customer’s limitations (as opposed to the team/product’s limitations)
    - listen to what they’re not telling you (they may be too agreeable, they may accept a problem because it’s “not that big of a deal” ‣
        
        *Many of you may be saying, “We talk to our customers all the time,*
        *and when we ask them about what frustrates them, they say they’re*
        *‘okay’ or they ask for something we can’t fix.”*
        
        *As you begin your investigation, talking with customers and lifting*
        *every rock, your team may become frustrated by the lack of valuable*
        *leads. While talking with customers is a great way to explore your customers’*
        *problems, it can be difficult to identify problems your team*
        *can actually solve.*
        
        *As an interviewer, it’s critically important to not only listen to what the*
        *customer is telling you, but also look for what they’re not telling you.*
        *Sometimes customers want to be agreeable and not come off as rude*
        *or complaining. They may accept a problem or inefficient workaround*
        *because it’s “not that big of a deal.” Without careful observation or*
        *attentive listening, you might overlook these types of problems.*
        
    - avoid problems not worth solving (ask what they’re doing to solve hte problem, how often they try, how much money they spend, how much time they spend)
        
        *Going back to our service provider website example, imagine we*
        *believed our service providers were frustrated because they didn’t have*
        *a website to promote their services. We believed there might be a service*
        *opportunity for us to help our providers build their own websites*
        *and host them within our portal.*
        
        *When we talked to our providers who didn’t have a website, we heard*
        *many frustrations. They complained about not having an online presence*
        *and how they wished creating a website could be easier for their business. They were frustrated because many of their competitors had websites, and they felt like it was a competitive advantage. In fact, some providers even suggested we offer a website creation service. One provider said, “I’ll give you my wallet!” if we solved this problem for him.*
        
        *This may seem like a problem worth solving. However, the desire to*
        *have a website is not the same as having a problem with not having a*
        *website.*
        
        *Imagine we had asked them questions like:*
        *• How are you getting around this problem today?*
        *• How often do you try to solve this problem?*
        *• How much time do you typically spend investigating solutions to*
        *this problem?*
        *• How much money have you invested to try to solve this problem?*
        
        *Many of our service providers said we should help them build their*
        *website, but when we asked them how they were currently addressing*
        *this problem, their responses were less than encouraging.*
        
        *For example, none of the providers we spoke to had spent any money*
        *to solve this problem (even the one who said he’d give us his wallet).*
        *Additionally, only a few had spent time investigating a solution. Many*
        *admitted that they hadn’t really thought about it until we brought it up.*
        
        *Therefore, we might conclude that while providers are frustrated about*
        *not having a website, it simply isn’t a problem they’re motivated to*
        *solve.*
        
        *So, we need to ask ourselves, “If customers aren’t willing to buy other*
        *products that solve this problem, what makes us think they’d be willing*
        *to buy our solution?”*
        
- brainstorming prompts for [problem]
    - *These [type of customers] are lacking the ___ that they*
    *need to get their job done.*
    - *This [problem] affects these [types of customers] in the following*
    *ways: .*
    - *These [type of customers] are doing to work*
    *around their problem.*
    - *These [type of customers] experience pain when they are*
    *[job-to-be-done].*
    - *This [problem] is small, but happens frequently.*
    - *This [problem] occurs infrequently, but is critical.*
    - *These [type of customers] have abandoned because of .*
    - *These [type of customers] are spending amount of*
    *time doing .*
    - *These [type of customers] are limited or constrained*
    *by .*
    - *These [type of customers] want to do [job-to-be-done] today*
    *but can’t, because [problem].*
- Factors that contribute to problems
    
    *Let’s return to our example website that helps customers find service*
    *providers in their area. There could be many factors that prevent our*
    *customers from successfully finding a provider:*
    
    - *Money*
        - *Customers are limited by the amount they can spend on services*
        *like house cleaning, childcare, and pool cleaning. Therefore, finding*
        *a service provider that is affordable is of high importance.*
    - *Time*
        - *Perhaps the customer doesn’t have a lot of time to spend looking*
        *for the right service provider. They may visit our site with an*
        *expectation of finding providers quickly, but leave in frustration*
        *because it takes too much time to filter results to find the provider*
        *they’re looking for.*
    - *Knowledge*
        - *Our customers could have a diverse set of knowledge and experience.*
        *Some might find the site too basic and would prefer advanced*
        *features, while others want an experience tailored to someone just*
        *getting started.*
    - *Confidence*
        - *Customers can put off decisions or lose motivation if they feel*
        *anxious or defeated. Great products engender trust and empower*
        *customers, giving them the confidence they need to achieve their*
        *goals.*
    - Skill
        - *Customers may have expertise with service providers and confidence*
        *they can navigate the web, but have limited skills when typing*
        *long messages on a keyboard. In this case, these customers*
        *may love the website, but find the process of completing contact*
        *forms for service providers daunting and laborious.*
- Example
    
    *For example, maybe we believe that, when office administrators create*
    *promotional brochures, they are frustrated by:*
    *• The lack of aesthetically pleasing designs*
    *• The time it takes to get started*
    *• Having to print the brochure correctly, so it can be folded the right*
    *way*
    *• Resizing images in the brochure and ensuring that they are still*
    *of premium print quality*
    
    *Therefore, if we wanted talk to customers about these problems, our*
    *Discussion Guide might look like this:*
    *• How do you feel about the design choices StarDoc gives you for*
    *creating a brochure?*
    *• About how long did it take you to get started with creating your*
    *brochure?*
    *• Talk to me about the process of printing the brochure.*
    *• How do you go about adding images to your brochure? What’s that*
    *process like for you?*
    

## step 5 brainstorm hypothesis from combinations of customers, motivs, jobs to be done, problems

> *We believe [type of customers] are motivated to [motivation]*
*when doing [job-to-be-done].*
> 

> *We believe [type of customers] are frustrated by [job-to-be-done]*
*because of [problem].*
> 
- Example: T Mobile Story
    
    *2012 was a tough year for T-Mobile. They suffered a major embarrassment*
    *when their merger with AT&T failed to get the necessary regulatory*
    *approval; and due to the company’s uncertain future, lack of*
    *support for the iPhone, and poor network coverage, they lost 800,000*
    *subscribers.1 This was a death knell for the small US wireless company,*
    *which had been trying to compete with the likes of behemoths*
    *like Verizon and AT&T. Many believed that T-Mobile’s days were*
    *numbered.*
    *At the beginning of 2013, CEO John Legere took the stage and*
    *announced that the company was headed in a new direction. He proclaimed*
    *that T-Mobile was going to be the country’s “un-carrier.”2*
    *Legree argued that consumers were frustrated with complex calling*
    *and texting plans, long-term contracts, and confusing surcharges.*
    *T-Mobile was committed to doing business differently, and their goal*
    *was to be unlike any other mobile carrier—by not acting like a carrier*
    *at all.*
    *On stage, Legere was bombastic, and at times vulgar, when describing*
    *the frustrations customers encountered when dealing with*
    *T-Mobile’s competitors. He wanted people to understand that he got*
    *their frustrations.*
    
    *T-Mobile was going to be different. They were going to speak plainly*
    *and honestly, and above all else, they were going to do right by their*
    *customers.*
    *Along with pumping four billion into upgrading their 4G LTE rollout,*
    *T-Mobile introduced their Simple ChoicePlan, which asked customers*
    *two simple questions: how many lines do you need, and how much*
    *data do you want? This plan was simple to understand and, more*
    *importantly, completely void of any contracts or legal jargon.*
    
    *This was a radical departure from what the competition was doing*
    *(see Figure 5-1). Instead of hiding behind outrageous contracts and*
    *complex legalese where they could hide fees and conspicuously raise*
    *rates, T-Mobile was going to make their offerings clear and simple. No*
    *games, no tricks, just wildly great customer service.*
    
    *The “un-carrier” approach, with its bold colors and edgy advertising,*
    *had a strong impact on customers’ perceptions of the company.*
    *T-Mobile had tapped into many customers’ frustrations with their current*
    *providers, and appeared to be empathetic and sincere in trying to*
    *improve their situation.*
    *T-Mobile could not compete head-to-head with its competitors when*
    *it came to device selection or network coverage, but customers were*
    *beginning to value T-Mobile as the authentic and scrappy underdog.*
    *That year, T-Mobile grew their subscriber base for the first time in*
    *4 years and, for the next 13 consecutive quarters, maintained over*
    *1 million added subscribers each quarter.3*
    *In short order, T-Mobile went from being at death’s door to being the*
    *country’s fastest-growing wireless company.4 Additionally, the company*
    *enjoyed outstanding customer satisfaction ratings, continually*
    *topping the list when compared to the competition.*
    
- Example: The Gillette Story
    
    *When Procter and Gamble (P&G) acquired Gillette, maker of razors*
    *and grooming products, P&G’s president of men’s grooming, Chip*
    *Bergh, became responsible for the new strategy. Although Gillette was*
    *already a successful company in the United States, Bergh was looking*
    *to leverage Gillette’s existing capabilities while identifying new*
    *growth opportunities. As part of his growth strategy, he wanted to*
    *expand Gillette’s business into new, emerging markets. This strategy*
    *led him to focus his attention on India.*
    
    *P&G, which is known for their customer-driven research, thought it*
    *would be best to take the entire team to India for two weeks. For the*
    *Gillette team, ethnographic research was a new practice; they’d built*
    *a very successful company using quantitative metrics to understand*
    *their customers. The idea of traveling all the way to India to learn more*
    *about customers seemed like a waste of resources. The Gillette team*
    *felt that they could easily gather the same insights from Indian men*
    *living in the United States, without having to incur the costs of a trip*
    *to India.*
    
    *Even though he was met with resistance, Bergh was finally able to*
    *convince the team to go to India. During their visit, the team spent*
    *time observing the mundane routines and practices of men shaving*
    *throughout the week. While many of the practices were the same as*
    *those of American men, the team quickly learned that there was one*
    *fundamental difference: many of the men in India were shaving without*
    *the use of running water. In fact, most of the men filled a single*
    *cup of cold water to shave.*
    
    *The team was mortified. It was difficult to watch these men struggle*
    *with their razors as they became clogged with hair, ultimately becoming*
    *ineffective and useless. To work properly, the Gillette razor technology*
    *required warm water to wash the blades clean. It had never*
    *occurred to the team that customers would be using their razors with cold water or without a large sink.* 
    
    *Their entire line of razors did not perform well under those types of conditions. The team had never considered asking questions about water usage and availability, because running water was plentiful in the United States.*
    
    *Excited that they had uncovered a new opportunity, in an emerging*
    *market, the team got to work on a new, single-blade razor specifically*
    *for markets without access to warm, running water.*
    
    *Within three months, the Gillette Guard razor was released in India*
    *and became the best-selling razor on the market (Figure 6-1).2*
    
- Example: Continuum + PG (Swiffer)
    
    *Let’s look at another example from Procter & Gamble. In 1994, P&G*
    *partnered with Continuum, a research and design firm, to help them*
    *identify new innovations in the category of home cleaning with the*
    *goal of generating $5 billion in revenue from new product lines.*
    
    *If we talked to customers about how they clean their floors, we imagine*
    *that many of them would say they use a broom and a mop, and that*
    *for the most part, that method is “okay.”*
    
    *To get around this, Continuum decided to not only talk with customers,*
    *but also to visit them at home and watch them clean their floors. A*
    *case study on Continuum’s website explains what they learned:*
    
    - *Mopping floors is a dirty job. It’s also tedious and time-consuming.*
    *During our visits, we watched people engaging in a largely*
    *unpleasant experience—one that involved direct contact with dirt*
    *and water and took far longer than it should have. People changed*
    *into old clothes beforehand, in anticipation of the messy task ahead. Then they swept the floors with a broom and dustpan. And once they finally got to work with their mop buckets, people spent just as much time and effort wringing out their mops as they did cleaning the floors.*
    
    *The team realized that the complete process of cleaning floors was*
    *problematic. It wasn’t any one single product that was creating friction,*
    *but rather the process itself.* 
    
    *What they observed, time and again, was that mopping floors was tedious and unnecessarily time-consuming. So, the design team decided to look for ways they could reinvent the way people mop. Watching how mops pushed dirt around and noting the fact that customers had to sweep before they mopped, the team began to wonder, “What if a mop could attract dirt to itself?”*
    
    *The team began looking at a process where disposable pads could be*
    *charged, electrostatically, to attract dirt while customers ran it across*
    *their floors. The product eventually became known as the Swiffer and*
    *was an astronomical success for P&G (Figure 6-2). In fact, by 2004, the*
    *Swiffer was in 25% of households and Businessweek listed it as one of*
    *its “20 Products That Shook the Stock Market.”*
    
    *There’s incredible power in identifying problems through customer*
    *behavior. These problems are often undiscovered because it’s part of*
    *the customer’s typical routine; they aren’t expressing them as problems*
    *since they’ve become accustomed to the limitation.*
    
- tips: getting the hypothesis right
    
    > *Expressing your assumptions [using a hypothesis] turns out to be a really powerful technique. It takes much of the subjective and political conversation out of the decision-making process and instead orients the team toward feedback from the market. It also orients the team toward users and customers.*
    > 
    
    A great hypothesis:
    • can be tested;
    • reduces risk;
    • is specific;
    • separates the person from their behavior;
    • focuses on the customer’s limitations, not your own; and
    • can be measured.
    
    Hypothesis tips
    
    - Focus on what customers care about, instead of what the product does
        
        Bad hypothesis: *We believe that, because our search algorithm produces ineffective*
        *results, customers are unwilling to create an account on our*
        *website.*
        
        *This inwardly focused hypothesis already biases us toward one solution*
        *(adjust the search algorithm so it produces better results). It*
        *doesn’t explore who the customer is, what they’re trying to do, and*
        *how poor search results affect them.*
        
        Good hypothesis: *We believe that customers without an account prefer to see their*
        *results in order of closest to farthest from their location when*
        *searching for providers on our website.*
        
        *This hypothesis connects the customer’s motivation to one of our site’s*
        *limitations.*
        
    - Be specific (type of customer, motivation job to be done)
        
        *Let’s say we want explore why customers might use this type of website.*
        *So we decide to try to validate the following hypothesis:*
        
        - *People want to save money on services.*
        
        *There’s a high likelihood that this hypothesis will be validated. After*
        *all, who doesn’t want to save money on services?! If we chose to use*
        *the validation of this hypothesis as justification to pursue our idea, we*
        *would be on shaky ground. In a sense, all we’ve validated is that people*
        *want to save money on services, not that they want to use a website to*
        *search for service providers.*
        
        *Additionally, this type of general hypothesis will lead to uninformative*
        *conversations with our customers. It doesn’t drill down to the specifics*
        *of the customer’s motivation and will generate customer feedback that*
        *is all over the map or unhelpful.*
        
        More specific:
        
        - *We believe working parents who have children under 12 are motivated*
        *to find quality childcare for an affordable price when searching*
        *the internet for service providers in their area.*
        - *We believe [type of customers] are motivated to [motivation]*
        *when doing [job-to-be-done].*
        - type of customer: working parents who have children under 12
        - motivation: find quality childcare for an affordable price
        - job-to-be-done: searching the internet for service providers in the area
    - separate the person from the behavior
        
        *For example, imagine we want to create a retention program to encourage*
        *customers not to leave our website that connects them to local service*
        *providers. We call these customers “churners”; they’ve created an*
        *account and engaged with the site for a couple of weeks, but haven’t*
        *returned in over a month. We might have a hypothesis about why they*
        *haven’t returned:*
        
        - *We believe churners left our website because they are no longer*
        *looking for a service provider.*
        
        *This seems like a legitimate reason for leaving our website; however,*
        *it’s lacking because it focuses only on the behavior of churning—not*
        *who the customers are and what motivated them to engage with us in the*
        *first place.*
        
        *How old are these churners? What is their level of skill or expertise*
        *with using the internet? Where do they live or work? What was their*
        *motivation for coming to our website in the first place? Did they fail*
        *to find a provider because there wasn’t a desirable one in their area, or*
        *because the search tool was too confusing to navigate?*
        
        ***It’s important to resist the urge to put the behaviors you’re trying to*
        *correct (e.g., slow adoption, bad reviews, refusal to upgrade to paid service)*
        *in your hypotheses. It wraps the customer’s identity around the*
        *negative behavior and makes it difficult to understand who they are*
        *and what truly motivates them.***
        
        *If our strategy were to focus only on correcting behaviors that don’t*
        *align with our business goals, we would end up distancing ourselves*
        *from our customers and fall into a combative “us versus them”*
        *mentality.*
        
        - *We believe customers who have limited knowledge of the internet*
        *find it difficult to search for providers on our website, because*
        *they don’t know what keywords can be used to narrow to produce*
        *meaningful results.*
        
        *This hypothesis gets at the heart of the type of customer and the*
        *unique problem they’re having (which is resulting in churn).*
        
    
    - Types of Data
        - Qualitative data: *Effectively, this data is used to approximate or characterize your customers. It may be characteristic attributes or customer quotes*
        *that perfectly capture a common sentiment. We often say that*
        *while a picture is worth a thousand words, a direct customer quote*
        *can be worth ten thousand words.*
        - Quantitative data: *During product development, we tend to rely on more traditional quantitative measures like satisfaction ratings or scores that determine intent to use. These numerical scores can be easily monitored*
        *and measured throughout your exploration.*
        - Soft Quantitative data: *“Soft” quantitative data is data that doesn’t have statistical significance. These are numbers that allow us to track if there’s a signal, without bringing in heavy formulas or statistical rigor. “Soft*
        *quant” measures are great when you’re trying to measure the*
        *effectiveness of a design iteration or the number of times a sentiment*
        *is expressed by a customer.*
            - *For example, we may decide we’re going to count the number of*
            *times customers express that a feature should be provided for free.*
            *If we talked to 10 service portal customers and 8 of them mentioned*
            *that our premium listings should be free, that would be a*
            *signal worth investigating.*
    

## step 6 pick a hypothesis

## step 7 create a screener

- getting screeners right
    
    Screener: a *series of specific questions that you can ask a customer*
    *before the interview to determine if they are the right fit for your study.*
    
    *Consider the following attributes for developing your screener:*
    *• Work environment*
    *• Job role*
    *• Skills and job responsibilities*
    *• Tools and technologies*
    *• Jobs/tasks they perform*
    *• The last time they performed the job/task*
    
    - Example
        
        *Let’s revisit our example website that connects customers to service*
        *providers in their area. Say we’re interested in finding out how well*
        *the relationships have been going between our customers and the*
        *local service providers they’ve contacted. We could set up a series of*
        *screener questions to ensure that we’re talking to the best possible*
        *candidates for our study:*
        
        *1. In the past six months, how often would you say you used our web*
        *portal?*
        *2. In the past six months, how often would you say you searched for*
        *a service provider?*
        *3. In the past six months, have you contacted a service provider to*
        *inquire about services?*
        *4. In the past six months, have you scheduled an appointment with*
        *a service provider for consultation?*
        *5. Are you currently receiving services from a provider you’ve contacted*
        *through our website?*
        
        *If a customer answers “very often” or “yes” to these questions, there’s*
        *a higher likelihood that they have enough experience with our portal*
        *to give us valuable insight into the relationships being established*
        *between our customers and service providers.*
        

## step 8 create a discussion guide

- tips: getting validation questions (”Discussion Guides”) right
    - Discussion Guides *help formulate the types of questions we will ask customers to validate our hypotheses*
    - don’t ask leading questions (e.g. what do you dislike about our search engine?)
    - *As an interviewer, you should be comfortable*
    *with “awkward silence” because it gives your customers a*
    *chance to reflect on the questions you’re asking them.*
    - *During the interview, you want to exude positivity. Continually encourage*
    *feedback and reassure customers that they won’t hurt your feelings*
    *with negative comments. The customer may feel like they’re failing*
    *the interview because they’re not telling you what you want to hear.*
    *You want to continually reassure them that any feedback is important*
    *and helpful, even when it’s tough criticism.*
    - *Cindy Alvarez suggests that human beings are all motivated by three*
    *simple desires:*
    *• We like to help others.*
    *• We like to sound smart.*
    *• We like to fix things.*
        - *We find this to be true as well. Any time we position the customer as*
        *the expert, we find they have a greater sense of duty and engagement.*
        *They feel empowered and have a greater desire to get involved and*
        *offer their expertise.*
    - Good example questions
        
        *1. Tell me about the last time you tried to search for a provider on our*
        *website. What was that experience like?*
        *2. How often are you able to successfully find a service provider you*
        *are looking for? How do you know you’ve been successful?*
        *3. How confident do you feel when searching our site? Do you feel*
        *like you’re able to find the best results? What makes you feel that*
        *way?*
        *4. Have you ever had trouble finding a provider on our website? How*
        *did that make you feel?*
        *5. If you could improve one thing about our search experience, what*
        *would it be?*
        
        *Notice how these questions are open-ended. They don’t evoke simple*
        *yes or no answers. Our Discussion Guides are intended to evoke a*
        *conversation.*
        
    - Capture anything meaningful. Some things to look for:
        - direct quotes
        - the customer’s environment
        - jobs they are performing
        - motivations
        - skills
        - tool use
        - expressed frustrations or limitations
        - delighters

Questions to validate customers

- Questions to validate [types of customers]
    - *What is your work environment like (e.g., size, physical surrounds,*
    *process maturity)?*
    - *What are some of the market pressures your company faces? What are some of the key marketplace trends that your company faces?*
    - *What things about your work environment would you characterize*
    *as being typical of other companies, and what things would*
    *you say are unique or exceptional?*
    - *What is your job title and what are your primary responsibilities*
    *at your company?*
    - *As a [type of customers], what high-level jobs/tasks do you perform?*
    - *As a [type of customers], what kind of skills, experiences, and personal*
    *characteristics do you need?*
    - *As a [type of customers], what platforms, tools, and technologies*
    *do you work with?*
    - *As a [type of customers], what other types of people do you work*
    *with?*
    - *As a [type of customers] what types of applications or services do*
    *you currently work on?*
- Questions to validate [motivation]
    - *What motivates you to do [job-to-be-done]?*
    - *If you didn’t do [job-to-be-done], what would be the consequences?*
    - *When you do a good job at [job-to-be-done], what does it look like?*
    *How do you feel?*
    - *When you start [job-to-be-done], what are you typically trying to*
    *achieve?*
    - *What are the benefits of [job-to-be-done]? What do you or your*
    *company get out of it?*
- Questions to validate [jobs-to-be-done]
    - *When doing [job-to-be-done] what are some of the specific jobs/*
    *tasks you perform?*
    - *How often are you personally involved in [job-to-be-done]?*
    - *Tell me who is involved in [job-to-be-done] at your company?*
    - *Tell me about how you do [job-to-be-done] today.*
    - *Is there anything specific that you typically do before or after you*
    *do [job-to-be-done]?*
    - *Are there multiple starting points for [job-to-be-done]? If so, what*
    *are they?*
    - *What products, services, or technologies do you or others at your*
    *company currently use when doing [job-to-be-done]?*
    - *Tell me about the last time you did [job-to-be-done].*
    - *What were the major problems/challenges you faced when doing*
    *[job-to-be-done]?*
- Questions that validate [problem]
    
    *• What’s your biggest frustration with [job-to-be-done]?*
    *• Were there things that you were lacking that you needed when*
    *attempting [job-to-be-done]?*
    *• When doing [job-to-be-done], what tools or workarounds have you*
    *used to get around [problem]?*
    *• How well do these workarounds address the [problem]?*
    *• How much time, effort, and money have you spent trying to work*
    *around [problem]?*
    *• When you are attempting [job-to-be-done], what are the “little*
    *things” that frustrate you? Do these things happen frequently?*
    *How often?*
    *• When you are attempting [job-to-be-done], what are the “big*
    *things” that happen infrequently but are problematic when they*
    *do happen?*
    
    *• Have you experienced a problem that stopped you from being able*
    *to complete [job-to-be-done]? Can you tell me what happened?*
    *• On a scale of 0–10 (where 10 is extremely affected), how affected*
    *are you by [problem]? Why?*
    *• If we solved [problem], what would it allow you to achieve?*
    *• If you could wave a magic wand and change anything about [jobto-*
    *be-done], what would it be?*
    
    *• Have you experienced a problem that stopped you from being able*
    *to complete [job-to-be-done]? Can you tell me what happened?*
    *• On a scale of 0–10 (where 10 is extremely affected), how affected*
    *are you by [problem]? Why?*
    
     *• Is [problem] a challenge for you?*
    *• If we solved [problem], what would it allow you to achieve?*
    *• If you could wave a magic wand and change anything about [jobto-*
    *be-done], what would it be?*
    
- Questions to expand customer feedback loop
    - *Is there anyone else that I should also be talking with? Is there*
    *anyone you know who is [type of customers]?  Is there*
    *anyone you know who is experiencing [problem] when attempting*
    *[job-to-be-done]?*
    - *May I contact you in the future if I have additional questions?*
    - *In the future, if we had some early product ideas around [job-to-be-*
    *done], would that be something you’d be interested in seeing?*

## step 9

interview customers / acquire info

## step 10

- debrief
    
    *• What stood out to you the most; what was most surprising?*
    *• What do you think motivates the customer? What are they trying*
    *to achieve?*
    
    *• What is preventing the customer from achieving their goals?*
    *• Did the customer express any problems or frustrations? What*
    *were they?*
    *• What similarities or differences does this customer share with*
    *other customers?*
    

## step 11

come up with a list of validated problems

## step 12

generative phase: how might we

*Take the problem(s) you want to solve and reframe them using “How might we?”*

Keep asking How might we, Why, What else, and What’s stopping that? 

*You should begin to identify problems that are smaller and more addressable.*

- Prompts. *As a team, look at the subsequent “How might we” questions and*
*respond with ideas. As you generate ideas, ask yourself:*
    - *What are the different ways we could solve this problem?*
    - *What barriers exist for the customer that prevents them from solving*
    *this problem?*
    - *What’s required of us to solve this problem?*
    - *What do we need to do (as a team, division, or organization) to*
    *solve this problem?*
- *Tip*
    
    *The strategy we employ to solve problems has an incredible effect*
    *on the corresponding solution. If our problem focus is too narrow,*
    *we miss the greater issues at play. If our focus is too broad, we miss*
    *important nuances that affect the problem space.*
    
    *Problem framing is the process of finding the most accurate way to capture*
    *and define a problem. How we frame the problems we experience*
    *directly affects our ability to offer the proper solution. Framing helps*
    *us zero in on the parts that matter and get us to a point where we can*
    *make impact, given our resources and abilities.*
    
- Example
    
    *For example, say we’re a small team of five people and we want to solve*
    *the problem of climate change. Now, that’s a big, very complex problem.*
    *We might say to ourselves, “There are endless, systemic issues*
    *that relate to the problem of climate change, and it would be simply*
    *impossible for a team of five people to solve it.”*
    *This, of course, frames the problem too broadly. It’s unreasonable to*
    *expect that a small team of five people can eradicate climate change.*
    *But what if they frame the problem a bit differently? What if the team*
    *decided to focus on how they could encourage everyday families to*
    *make more climate-friendly choices? Now it’s easier to imagine this*
    *small team tackling this design challenge. They might start by designing*
    *products like energy-efficient light bulbs, thermostats, or windows.*
    *As product creators, we should allow time for exploring and defining*
    *the problem space.*
    
- Formulating ideas (generative phase): Use “How might we?”
    
    *The most creative teams maintain a supportive environment and space*
    *to explore ideas and share them without fear of judgment.*
    
    *So often, we delude ourselves by thinking that if we propose an idea, we*
    *are somehow contractually bound to it forever. What we forget is that*
    *ideas are cheap; they cost us very little. They can be easily refined or*
    *discarded. Building the wrong thing, however, is incredibly expensive.*
    
    *Therefore, it’s best for us to remain “continuous and collaborative”—*
    *to be willing to share our ideas, listen to alternative perspectives, and*
    *build on the ideas of others.*
    
    *Tom and David Kelly, founders of the world-class design agency IDEO,*
    *believe that continuous collaboration is a core component to creative*
    *exploration*
    
    > *At IDEO, we seldom say, “That’s a bad idea” or “That won’t work”*
    *or “We’ve tried that before.” When we disagree with someone*
    *else’s idea, we push ourselves to ask, “What would make it better?*
    *What can I add to make it a great idea?” Or, “What new idea*
    *does that spur?” By doing so, we keep creative momentum going*
    *instead of cutting off the flow of ideas. Throwing cold water on*
    *one person’s contribution can bring conversation to a halt; it is the*
    *back and forth of ideas that can lead you to new and unexpected*
    *places.*
    > 
    
    *Dr. Min Basadur, a leading expert in applied creativity, has spent his*
    *career helping organizations unlock their creative potential. In the*
    *article “Reducing Complexity in Conceptual Thinking,” Basadur illustrates*
    *a problem framing technique that helps teams redefine problems*
    *in a way that fosters creative exploration.6 It starts with a fundamental*
    *question:* 
    
    *“How might we?”*
    
    ![image.png](attachment:532a038a-51db-4fcd-ad95-4366ff39ee97:image.png)
    
- Keep recursively asking
    
    ![image.png](attachment:9786f9c4-1361-47be-8258-08f2caededd8:image.png)
    
    *The trick is to find the right articulation of the problem—that is, the*
    *one that generates the most ideas. Most often, this happens organically.*
    *Some teams will start with a broad problem (e.g., “How might we solve the crisis of climate change?”) and work their way down to something more manageable (e.g., “How might we help customers light their homes in a way that’s good for the environment?). Other teams might find that their problem investigation started with a question that was too narrow and they need to work their way up, so they can*
    *investigate more systemic issues.*
    

## step 12

measure the opportunity of fixing each problem

- Discriminative phase: measuring the opportunity (cost, risk, etc)
    - Cost
        
        *Depending on your resource availability, you may decide to prioritize*
        *your ideas based on their estimated development cost.*
        *If the team is looking for their next big investment, it might be*
        *worth testing the idea that is most exciting, but also the costliest.*
        *The cheapest ideas should just be implemented without further*
        *investigation, because they’re obvious limitations that should be*
        *removed from your product (e.g., software bugs).*
        
    - Risk
        
        *You can prioritize your ideas based on product risk. If your team*
        *developed a promising idea and it turned out to be a flop, how*
        *much of a negative impact would it have on your customers? Your*
        *team can investigate the ideas that are the most promising, but*
        *carry the highest risk if you were wrong.*
        
    - Customer Impact
        
        *Based on your ongoing communication with customers, you*
        *can organize ideas around what you believe will have the most*
        *impact on, or generate the highest satisfaction from, your customers.*
        *Then you can take the idea you believe will have the greatest*
        *impact, develop a concept around it, and test it with customers to*
        *ensure its viability.*
        
    - Differentiation
        
        *You can organize your ideas based on their uniqueness compared*
        *to solutions provided by your competitors. The most differentiated*
        *ideas may be the ones worth pursuing. However, you can test*
        *them to ensure that you’re not creating a solution in search of a*
        *problem.*
        
    - Business Goals
        
        *Your organization may have an overarching business goal, such as*
        *entering a new market, getting customers to upgrade to the latest*
        *version, or encouraging in-app purchasing. You can prioritize the*
        *ideas that you believe will best align with your organization’s business*
        *goals. At this stage, you might be making your best guess,*
        *but that’s okay. You can always validate the idea with customers,*
        *against these business goals, as you refine the idea into a concept.*
        

## step 13

categorize them on the impact/effort matrix

- Discriminative phase: The Impact/Effort matrix
    - Quick Wins (High Impact, Low Effort)
        - *Ideas that have a high impact on the customer, but require a little*
        *amount of work, should be obvious wins. These are projects*
        *that are low-hanging fruit, so you should just plan to make these*
        *changes.*
    - Long-term Strategy (High Impact, High Effort)
        - *These are ideas that could have a tremendous impact on customers,*
        *but they’ll require a significant investment from your team.*
        *These ideas won’t materialize overnight, so you’ll have to be strategic*
        *and create a long-term plan to bring them to fruition.*
    - Pet Projects (Low Effort, Low Impact)
        - *These ideas have little direct impact on customers, but don’t cost*
        *that much in terms of time invested or resources. These might*
        *be personal projects or fixes that are a sort of “spring cleaning”—*
        *things that need to be done but probably don’t justify the team’s*
        *entire focus.*
    - Thankless Tasks (High Effort, Low Impact)
        - *These are projects that will require a significant investment, but*
        *won’t likely produce any immediate or direct benefit for the customer.*
        *These could be underlying platform changes to software*
        *code or a restructuring of tools and processes to make the team*
        *more efficient. Like pet projects, these tasks can be hard for the*
        *team to justify, but they could lead to critical issues down the road.*
    
    ![image.png](attachment:ce31b2da-beca-4b9c-ae55-7b2f20f20483:image.png)
    

For each idea, answer the following questions:

- How much effort will it take to implement this idea?
- How much impact will this idea have on the customer?
- How much impact will it have on the customer if we don’t
implement this idea?

Then put it on the Impact/Effort matrix

## step 14

pick the priority idea

## step 15

define the criteria for the priority idea

*At this point in the HPF, you should have validated the [type of*
*customers], [problem], and [job-to-be-done]. Capture those parameters*
*on Post-it notes and place them on the hypothesis template*
*to fill in the blank parameters.*

Now, define [criteria]. *You’ll need to define the criteria by which you will evaluate your concept’s success. Measures such as need fulfillment, intent to use, believability, differentiation, and the willingness to recommend the concept*
*to a friend or colleague are helpful criteria to measure the success of*
*your concept.*

## step 16

name the benefits for solving this idea in this way

- Benefits
    
    *Each concept has a series of benefits. The benefits should not focus on*
    *specific implementation details but rather on the value the customer*
    *will receive by using your concept.*
    
    *In the case of Provider Pro Plus service, the benefits would be all*
    *the feature ideas that we generated during our “How might we?”*
    *brainstorm.*
    
    *The Provider Pro Plus will:*
    *• Allow you to configure a website in just three easy steps.*
    *• Automatically pull your business details from your profile, and*
    *put them into a stylized web template.*
    *• Track visitors to your site and email you a weekly “activity report.”*
    *• Provide a “Contact Us” form. Submissions get sent to your email*
    *address.*
    
    *You can introduce these benefits in short (one- or two-sentence)*
    *descriptions. Much like the overall unique value proposition, we’re*
    *interested in the customer’s perceptions of what these benefits mean*
    *to them. We’re interested in their questions because those will highlight*
    *the things they care about. For example:*
    
    ***Customer**: “Does the activity report include pages they actually*
    *visit on my site?”*
    
    ***Interviewer**: “Is that something you would need? How would*
    *that be helpful to you?”*
    
    ***Customer**: “Well, yeah…My shop has a bunch of automobile*
    *detailing and repair services we provide, so I guess I’d want to*
    *know which services people visited the most.”*
    
    *You can also have the customer rank the benefits in order, from “most*
    *impactful” to “least impactful.” This helps the team prioritize the benefits*
    *of the concept and establish where the cutline is for their MVP. By*
    *asking the customer to rank the benefits, you’re able to see what’s most*
    *valuable and what’s less valuable to them.*
    
- Prompts: Benefits.  *think about the minimum*
*number of benefits that you can include in the concept while still*
*providing value to the customer.*
    - *With this concept, the customer can .*
    - *This concept does a good job at .*
    - *The customer will find this concept valuable because it .*

## step 17

name the limitations of solving this idea in this way

- Limitations
    
    *Even the best concepts have limitations. The team should reflect not*
    *only on the things that the concept will do, but also what it won’t do. It’s*
    *important to be honest and transparent about your concept’s limitations.*
    *It’s better to learn what limitations will prevent customers from*
    *using your concept before you start building it.*
    
    *You can reveal your limitations much like you revealed your benefits,*
    *in one- or two-sentence descriptions.*
    
    *The Provider Pro Plus will not allow you to:*
    *• Modify source code or change underlying CSS files.*
    *• Host files over 100 MB in size.*
    *• Export data collected from online forms.*
    *• Provide administrative access to other users.*
    
    *As with the benefits, you’ll also have the customer rank limitations*
    *in order of “most impactful” to “least impactful.” This will help you*
    *identify the biggest barriers preventing customers from using your*
    *concept.*
    
    *Note, however, that what you think is a dealbreaker limitation may not*
    *be a limitation at all. For example, imagine that our service providers*
    *liked the idea that they couldn’t modify the source code of their websites.*
    *They felt that if we provided tools to manage code, it would make*
    *the experience too intimidated and confusing. They actually liked that*
    *we were hiding the code from them and saw it as a benefit.*
    
    *This understanding would save our team countless hours because we*
    *would avoid investing in features that customers won’t use. Imagine*
    *how much effort we might have wasted building tools for providers to*
    *modify source code, only to find out later that no one used them.*
    
    *These types of discoveries are what make CVTs so valuable.*
    
- Prompts: Limitations. think about: *Will you still be able to achieve the MVP if this limitation is present?*
    - *The customer can’t _ with this concept.*
    - *When customers begin to use this concept, they won’t be able*
    *to .*
    - *Customers may be frustrated by the lack of .*
    - *Due to technical limitations, the customer won’t be able*
    *to .*

## step 18

create UVP based on benefits and limitations

- Unique Value Proposition (UVP)
    
    *Every concept should propose a unique idea, or value proposition. In*
    *the business world, you might refer to this as your “elevator pitch.”*
    *Essentially, you’re describing to the customer, as clearly and succinctly*
    *as possible, how your concept is unique and worth paying attention*
    *to.*
    
    *After revealing your concept’s value proposition, you can ask customers,*
    *“How do you feel about this?” or “If something like this was available*
    *to you, how might you use it?”* 
    
    *You can also show them a storyboard that walks through a few of the high-level touch points of the experience. The trick is to provide just enough detail so the customer “gets it,” without going into too many specifics. Keeping your value*
    *proposition or storyboards a little bit vague allows the customer to fill*
    *in the experience with their own preconceived notions.*
    
    *For example, imagine we’re going to offer a website creation service*
    *for our service providers on our website portal. Our value proposition*
    *might sound like this:*
    
    - *The Provider Pro Plus service helps you create your own business*
    *website. Provider Pro Plus gives you access to hundreds of readymade*
    *website templates; they’re easy to configure and look fantastic.*
    *All the templates are hosted on our servers and have a guaranteed*
    *uptime of 99.9%.*
    
    *This description generates a lot of questions: “What would it cost?*
    *What do the templates look like? What options can I configure in the*
    *templates? What does 99.9% uptime mean?” This is intentional. We*
    *want to hear the types of questions the customer asks because those*
    *are the questions that we’ll need to answer when/if we release this*
    *solution. If a customer does ask a question about implementation, you*
    *can always turn it back to them (e.g., “What options would you expect*
    *to configure in the templates?”).*
    
    *Allowing customers to fill in the blanks is a valuable exercise. It helps*
    *you validate your assumptions or highlight parts of the experience you*
    *may have overlooked.*
    
- Prompts: UVP. use the following questions to stimulate conversation with the
team to generate the unique value proposition:
    - Who is this concept meant for?
    - What will the customer achieve by using this concept?
    - When will customers find this concept valuable (specific
    period, during a particular activity, job/task)?
    - Why should the customer care (saves them time, money,
    resources, etc.)?
    - How is it different than other solutions?

## step 19

Create Concept Value Test (CVT) by taking the Concept (UVP + Benefits + Limitations) and adding rating scales

- Example: VCR vs VHS (Sony LV-901 Betamax vs JVC) Story
    
    *During the holiday season in 1975, Sony released a device that, they*
    *believed, would change American households forever. They suggested*
    *it was as important as the invention of the telephone and told their customers*
    *it would allow them to “break the time barrier.”9*
    *Sony called it the LV-901, but most came to know it as the Betamax*
    *(Figure 7-5).*
    *The device debuted in retail stores at a hefty price tag of $2,295.10*
    *While the Betamax was heavy and bulky, Sony still claimed that it was*
    *a state-of-the-art design. It included a cassette recorder that consumers*
    *had never seen before, an analog clock, and a 19-inch, full-color*
    *Trinitron display.*
    *Betamax was the first in-home video cassette recorder (VCR). While it*
    *had many features, its chief selling point was the fact that customers*
    *could finally record television shows. With today’s DVR, on-demand,*
    *and online streaming services, it’s inconceivable that we would miss*
    *our favorite television program, but in the 70s it was a problem for*
    *many television watchers.*
    *A year later, JVC, makers of a similar video recording concept, introduced*
    *their format of tape and video recorders, which they called*
    *VHS (Video Home System). Thus began the entrenched rivalry of the*
    *“video format war.”11*
    
    *For the time, this was a rivalry on par with Mac versus PC or iPhone*
    *versus Android. Anyone who followed video formats had an opinion*
    *about which recording format was better, and heated debates over the*
    *topic weren’t uncommon.*
    *When JVC entered the market, Sony already had a commanding position.*
    *Sony had a video format that was widely considered superior in*
    *quality and durability, and their brand was emerging as a strong player*
    *in American consumer electronics. Even with all this wind in their*
    *sails, however, Betamax was a complete failure and JVC’s VHS format*
    *beat them in a landslide.*
    *How did this happen?*
    *There was no question that consumers wanted the ability to record*
    *their television programs at home. For all intents and purposes, we*
    *can agree that the problem hypothesis had been clearly validated.*
    *However, Sony and JVC had fundamentally different approaches to*
    *solving the problem. Conceptually, Sony valued quality, precision, and*
    *design, whereas JVC focused on affordability and availability.*
    *One of the critical differences between Betamax and VHS was the*
    *amount of recording time. Betamax cassettes were substantially*
    *smaller than VHS cassettes, so they were more limited in the amount*
    *of tape they could hold. Betamax tapes could record only an hour of programming, whereas VHS tapes could record up to four hours. Sony*
    *believed that, because most television shows were less than an hour,*
    *the lower recording time was a worthwhile tradeoff for better-quality*
    *video recording.12 JVC, on the other hand, was willing to accept lesser-*
    *quality recording to ensure that their cassettes were inexpensive.*
    *Soon, small businesses were popping up to rent movies to customers*
    *so they could watch them at home. Many customers at this point*
    *couldn’t afford their own VCR, so they would often rent one along with*
    *the movie they wanted to watch.*
    *These business owners had to decide which format they wanted to*
    *carry in their stores because it became too costly to buy every movie*
    *in two formats. Because the VHS format was cheaper and the players*
    *were more readily available, it slowly became the standard for home*
    *movie rentals.*
    *In other words, the availability of VHS in rental stores helped JVC’s*
    *format quickly become the standard that consumers associated with*
    *home video entertainment.*
    *At the end of the day, Sony was solving the right problem (“I want to*
    *record my favorite TV show and watch movies at home”) and they were*
    *also first to market. However, they were unsuccessful in solving the*
    *problem in a way customers found valuable. Sony focused their efforts*
    *on creating a product that had superior video and audio quality. While*
    *this might have been important to some consumers, most customers*
    *wanted affordable tapes and VCR players. In short, customers weren’t*
    *willing to pay the premium for superior quality.*
    *If Sony had asked customers, “Would you like to have superior*
    *audio and video quality when recording programs?” they would have*
    *undoubtedly said yes. However, if Sony had asked customers, “How*
    *important is quality compared to the price of the VCR or the amount*
    *you can record on single tape?” customers may have been willing to*
    *trade quality for other benefits. That would’ve been an important discovery*
    *for Sony as they began to prioritize the development of Betamax.*
    *By testing the benefits and limitations of your concept, you’ll determine*
    *the minimum number of features to include in your solution*
    *while still delivering value to your customer. This cost-benefit tradeoff*
    *is what leads you to your minimum viable product (MVP).*
    
- Example: USAF Story
    
    *In 1950, the United States Air Force had a mission-critical problem.*
    *Pilots were having trouble controlling their aircraft and, thus, crashes*
    *and deaths were on the rise.1*
    *The Air Force was a relatively new military expansion and the country*
    *was teetering on the edge of war with Korea. Now was not the time for*
    *officials to start losing confidence in their pilots’ ability to fly newer*
    *aircraft.*
    *So teams set out to discover the problem. Engineers ran tests on the*
    *planes, instructors reviewed their training programs, and investigators*
    *considered the possibility of pilot error. However, these factors did*
    *not appear to have a significant effect on the planes that had crashed.*
    *It was then that the Air Force considered the experience of the cockpit*
    *itself.*
    *Over two decades earlier, the Army had designed the first cockpit*
    *based on the average pilot’s height, weight, arm length, and other*
    *physical dimensions (see Figure 7-1). The size and shape of the seat,*
    *the distance to the pedals and stick, the height of the windshield,*
    *and even the shape of the helmets were all built using these averaged*
    *measurements.2*
    *If you’ve ever had trouble determining your proper clothing size from*
    *the labels Extra Large, Large, Medium, or Small, then you have no*
    *doubt experienced the frustration of the “average size.”*
    *It occurred to the Air Force that perhaps the cockpit of their aircraft*
    *was too small. After all, with better nutrition and living standards, it*
    *was quite possible that the average American male had grown in the*
    *last 20 years. (Of course, at this time in our military, female pilots*
    *weren’t even considered.)*
    
    *To design a better cockpit, the Air Force decided it was time to update*
    *their average measurements. Researchers at Wright-Patterson Air*
    *Force Base in Ohio began creating new measurements from more*
    *than 4,000 pilots. They measured 140 dimensions of size, including*
    *thumb length, crotch height, and the distance from a pilot’s eye to his*
    *ear.3*
    *A 23-year-old researcher named Gilbert S. Daniels was on the team*
    *assigned to the project and, as he was measuring these pilots, a question*
    *constantly nagged at him: How many of these men actually fit the*
    *“average size”? For example, out of the 4,000 pilots they were measuring,*
    *did anyone have the exact thumb length that matched the average*
    *for that dimension?*
    *So Daniels looked at all the measurements the team had so far. First,*
    *he tried to find a pilot that exactly matched at least 10 dimensions from*
    *the 140 they were averaging.*
    *He found no one matched at least 10 dimensions.*
    *Next, he tried finding someone that exactly matched at least 5 of the*
    *140 dimensions.*
    *Again, not a single pilot matched at least 5 dimensions.*
    *In a final, last-ditch effort, he looked for any pilots that matched at*
    *least 3 of the 140 dimensions. Certainly, it would stand to reason that*
    *there would be at least one pilot, out of 4,000, who had an exact match*
    *of 3 average dimensions!*
    
    *He found none.*
    *In his 1952 report, “The Average Man,” Daniels concluded:*
    
    > *The “average man” is a misleading and illusory concept as a basis*
    *for design criteria, and is particularly so when more than one*
    *dimension is being considered.*
    > 
    
    *Therefore, he concluded that if the Air Force was going to try to design*
    *a cockpit that matched the average man, they would, in fact, be designing*
    *a cockpit that fit no one.*
    
    *The Air Force hadn’t considered looking at the problem this way. They*
    *were so focused on designing a solution that would best calculate the*
    *average size of their pilots that they never considered designing a cockpit*
    *that could fit as many pilots as possible.*
    
    *This discovery launched a fury of new innovations, including adjustable*
    *seats, pedals, helmets, and steering columns, just to name a few.*
    *Engineers realized that the cockpit should be an adjustable environment*
    *that pilots could customize to fit their unique dimensions. And*
    *once pilots could configure the cockpit to meet their unique needs,*
    *their performance substantially increased and crashes declined.*
    *Adjustable cockpits also had an unintended benefit. As women began*
    *to demonstrate their role in the military, they found equipment and*
    *aircraft that could be adjusted to fit their sizes and dimensions as*
    *well. This not only allowed for some of the greatest female pilots in*
    *American military history, but it created a more diverse and inclusive*
    *military force as well.*
    

- Make a Concept Value Test: *unique value proposition (UVP) + benefits + limitations + series of questions that allow the customer to rate the concept.*
    
    *The approach we use to test our concepts with customers and get*
    *their feedback is called the Concept Value Test (CVT). Customers can*
    *evaluate your early thinking, give you feedback, and help you assess*
    *whether you’re presenting enough value with your concept.* 
    
    *A CVT consists of a unique value proposition that explains the*
    *concept, a set of benefits and limitations, and a series of questions*
    *that allow the customer to rate the concept.*
    
    *Let’s look at the components of the CVT and how they work.*
    

- Rating scales - solve a problem?  believability? different? would recommend?
    
    ![image.png](attachment:0a3c1252-65c6-49bd-9ea9-c1f4c95c71dc:image.png)
    

*Concepts are well-articulated ideas that describe the unique*
*value proposition, benefits, and limitations. Ideas that we believe will not only solve the problem, but do it in a way that customers find valuable.*

- Usefulness, most important benefits, “dealbreaking” limitations, likelihood of use, shared values
- ”Will this concept solve their problem? Do they find it valuable? Is it The Right Thing?”

> We believe that [concept] will solve [problem] and be valuable to [type of customers] while doing [job-to-be-done].
> 

> We will know this to be true when we see [criteria]
> 

Tips CVT:

- Test one approach at a time
    
    *The most important aspect of the Concept Value Test is that it challenges*
    *you to have a clear, articulated opinion about how you plan to*
    *solve the problem. You might be asking, “Why don’t I just show customers*
    *all of our concepts and have them tell me which one they like*
    *best?” This is an ineffective approach because you’ve moved the onus*
    *of solving the problem to the customer. It’s not the customer’s job to*
    *find the right solution—it’s yours!*
    
    *Therefore, encourage your team to have an opinion about the concept*
    *you’re considering. If you genuinely welcome the customer’s honest*
    *feedback, your customers will be willing to tell you if your opinion is*
    *lacking the right perspective.*
    
    *You can certainly run multiple CVTs in parallel, but you should*
    *refrain from showing a single customer multiple CVTs that use different*
    *approaches to solve the same problem. First, it’s cognitively overwhelming*
    *to evaluate multiple options, and second, customers can be biased to favor a concept, based on the order in which the concept was received.*
    
    *To keep things simple, work together to come up with a single concept,*
    *test it with customers, and refine that concept based on customer feedback.*
    *You’ll always have your alternatives in your back pocket, should*
    *you need them for future iterations.*
    
- CVTs don’t have to require a lot of effort
    
    *One of the most valuable things about Concept Value Testing is the*
    *fact that it requires very little effort to put one together. We’ve successfully*
    *run CVTs without a single image, wireframe, or workflow.* 
    
- *Recognize That Concept Value Tests Are Not Usability Tests*
    
    *CVTs are not usability tests. In other words, we’re not testing specific workflows,*
    *UI elements, or interactions. That sort of refinement will happen*
    *at the Feature stage.*
    
- *Sharpen the Language Surrounding Your Concept*
    
    *An extremely valuable byproduct of going through the CVT process*
    *is that teams learn how to effectively communicate their MVP. After*
    *talking with customers, ranking benefits and limitations, and examining*
    *rating scales, the team begins to understand what’s important*
    *about the concept and what isn’t. Throughout the process, your team*
    *will revise the words you use to describe the benefits and limitations*
    *of your concept. These words will be useful in the Feature stage, where*
    *you must clearly state what it is you’re building (and what you’re not*
    *building).*
    

## step 19

Create storyboard

When running it by customers:

- Make a storyboard and run it by them using a storyboard:
    
    *Your concept is not just a collection of features; it’s an experience,*
    *derived from multiple touch points. Storyboarding can be an effective*
    *tool to help illustrate the experience a customer will have with your*
    *concept.*
    
    *The story of your concept can take shape over each frame of the storyboard.*
    *We like to start with a three-frame storyboard that shows the*
    *“broad strokes” of the experience. These three frames can show the*
    *story of the customer before your concept is introduced, during, and*
    *after (Figure 7-4).*
    
    *Underneath each frame, it’s a good idea to write a sentence or two to*
    *describe what it represents.*
    
    *When starting your storyboards, here are some things you could*
    *consider:*
    *• What is the motivation of the customer? What are they trying to*
    *achieve in your story? ([motivation])*
    *• What task is the customer is engaged in? ([job-to-be-done])*
    *• What’s preventing the customer from achieving their goal? ([problem])*
    *How does it make the customer feel?*
    *• What solution is introduced to help the customer overcome their*
    *limitations? ([concept])*
    
    *You can show these storyboards to customers to get feedback on their*
    *accuracy. You can ask customers questions like: “Does this story resonate*
    *with you? Is this something you’re familiar with? Have you ever*
    *experienced anything like this story?”*
    

Storyboarding: 

*There are two things you need to get others onboard with your vision:*
*• A compelling story*
*• A way to share it*
*The most important thing about sensemaking is that it helps you*
*share meaning, not data. Data is important, but emotion and empathy*
*are what compel others to action.*

*The keyframes are the three fundamental events in the customer’s*
*journey (i.e., before, during, and after). You can always add more*
*frames if you need to.*

- Prompts: *first frame, describe the beginning of the story, the customer,*
*and the problem they’re experiencing performing a job/*
*task.*
    
    *{ Who is the customer?*
    *{ What are their motivations?*
    *{ What is their work environment like (e.g., size, physical surroundings,*
    *process maturity)?*
    *{ What job/task are they trying to accomplish?*
    *{ What problems do they encounter when performing the job/*
    *task?*
    *{ How do they feel when they have this problem?*
    *{ What do they do in response to this problem?*
    
- Prompts: second frame, *capture how the team’s concept will solve*
*that problem*
    
    *{ What problem is this concept solving?*
    *{ How does the user feel when they use this concept?*
    *{ How does this concept change their behavior?*
    *{ What can the customer do with this concept that they couldn’t*
    *before?*
    
- Prompts: third frame, the *end of the story, the outcome*
*the user will achieve by using the team’s concept*
    
    *{ What does the customer accomplish while using this concept?*
    *{ Has this concept alleviated their problem or limitation?*
    *{ How do they feel when they reach their goal/outcome?*
    

Tips storyboarding

- Keep your storyboards a little bit vague
    
    *You can also show them a storyboard that walks through a few of the high-level touch points of the experience. The trick is to provide just enough detail so the customer “gets it,” without going into too many specifics. Keeping your value*
    *proposition or storyboards a little bit vague allows the customer to fill*
    *in the experience with their own preconceived notions.*
    
    *This description generates a lot of questions: “What would it cost?*
    *What do the templates look like? What options can I configure in the*
    *templates? What does 99.9% uptime mean?” This is intentional. We*
    *want to hear the types of questions the customer asks because those*
    *are the questions that we’ll need to answer when/if we release this*
    *solution. If a customer does ask a question about implementation, you*
    *can always turn it back to them (e.g., “What options would you expect*
    *to configure in the templates?”).*
    
    *Allowing customers to fill in the blanks is a valuable exercise. It helps*
    *you validate your assumptions or highlight parts of the experience you*
    *may have overlooked.*
    

## step 20

run it by customers

- *Present the unique value proposition and storyboard. Present the “elevator pitch” and walk the customer through your storyboard*
*(if you have one):*
    - Storyboard
        
        *1. Introduce the concept by sharing a simple description of the concept,*
        *the “elevator pitch.”*
        *2. Optionally, use the storyboard alongside the elevator pitch to help*
        *convey the function, value, or utility of the concept.*
        *3. Allow the customer time to think about the concept you’re exploring,*
        *remembering that they’re seeing the concept for the first time.*
        *4. Ask the customer to provide feedback on the concept.*
        *5. If the customer responds, “I’d need to know more,” ask them what*
        *questions they have at this point. You don’t need to jump ahead*
        *and provide details, just capture what they would expect the concept*
        *to do, how it should behave, and what value it provides, if any.*
        
    - Benefits
        
        *1. Explain that the concept has multiple benefits, but that you’re*
        *going to reveal them one at a time.*
        *2. After each benefit, pause and ask the customer if the benefit is*
        *important to them and why.*
        *3. Ask the customer to rank the benefits from most impactful to*
        *least impactful.*
        *4. Once they’ve ranked the benefits, ask them why they ranked them*
        *in that order.*
        
    - Limitations
        
        *1. Explain to the customer that the concept also has limitations that*
        *you would like to explain, revealing them one at a time.*
        *2. After each limitation, pause and ask the customer if the limitation*
        *impacts them and how.*
        *3. Ask the customer to rank the limitations from most impactful to*
        *least impactful.*
        *4. Once they’ve ranked the limitations, ask them why they ranked*
        *them in that order.*
        *5. Ask the customer which, if any, of the limitations would prevent*
        *them from using the concept as a solution.*
        
    - Rating scales
        
        *1. Explain to the customer that you’d like them to provide feedback*
        *on the overall concept, considering the benefits and limitations.*
        *2. Ask the rating questions that you’ve captured in your Discussion*
        *Guide.*
        

## step 21

ask them validation questions

*After you’ve introduced and explored the concept with the customer, use the second set of questions to validate or invalidate that the concept solves a problem*
*the customer is experiencing in a valuable way.*

- Validate [concept]
    
    *• How important is this [concept]?*
    *• How well would [concept] solve a problem or fulfill a need for you?*
    *• How different is [concept] from other solutions currently available?*
    *• Are you using a solution that’s like [concept]? If so, how satisfied*
    *are you with it?*
    *• Is there anything that [concept] does a good job at?*
    *• Is there anything that [concept] does a bad job at?*
    *• What are your overall thoughts about [concept]?*
    *• When you think of other products like [concept], what are they*
    *good at?*
    *• When you think of other products like [concept], what are they not*
    *as good at?*
    *• How valuable is [concept]? Why do you feel that way?*
    *• If [concept] were available to you today, would you use it?*
    *• At what times would you use [concept]?*
    *• In what ways would you use [concept]?*
    *• Assuming [concept] were available on your job, would you download*
    *the trial today?*
    *• How do you feel about buying/recommending/subscribing to a*
    *product or service that provided [concept]?*
    *• Would you recommend [concept] to a friend or colleague?*
    
- Ratings: have people rate your CVT
    
    *During the CVT, we will get rich, qualitative responses from our customers*
    *about the concept we’re presenting, but we’ll want to collect*
    *quantitative data as well. Since we typically work with small sample*
    *sizes for CVT, we consider these “soft quant” measures. We’re not*
    *looking for statistical significance in our findings; we just want to determine if we’ve “moved the needle” with our concept. As the concept*
    *evolves, we’ll be able to monitor and compare customers’ ratings*
    *to judge the effectiveness of our iterations.*
    
    *After we walk customers through the concept’s value proposition, benefits,*
    *and limitations, we ask them the following questions.*
    
    - *WOULD THIS CONCEPT SOLVE A PROBLEM OR FULFILL A NEED FOR YOU? (1: definitely would not, 5: definitely would)*
        - *WHY TO ASK THIS. When talking with customers about your concept,*
        *you have an opportunity to continue validating your Problem hypothesis.*
        *In other words, you should always check that you’re solving the*
        *right problem.*
        - *WHAT TO LISTEN FOR. Listen for responses like:*
            - *“I don’t have this problem, but I know a lot of other people who*
            *do.”*
            - *“I don’t have this problem, but this is still a great idea.”*
        - *If you’re hearing this sort of sentiment from many customers, it may*
        *be an indication that your concept isn’t solving the right problem for*
        *this type of customer. You may consider revising your customer segment*
        *or choosing to focus on solving a different problem.*
    - *ASSUMING THIS CONCEPT WAS AVAILABLE TODAY, WOULD YOU TRY IT? (1: definitely would not, 5: definitely would)*
        - *WHY TO ASK THIS. This question helps you determine how willing the*
        *customer is to try this concept. If the customer is frustrated with the*
        *problem you’re trying to solve and thinks your concept solves it, then*
        *you should expect a high rating.*
        - *WHAT TO LISTEN FOR. Listen for red flag responses like:*
            - *“I don’t have this problem right now, but if I did, I’d definitely try*
            *this.”*
            - *“I don’t have time right now, but when I get some free time, I’d be*
            *willing to check out your concept.”*
        - *These are indications that you’re solving a problem, but not a problem*
        *that customers are experiencing right now. Additionally, they may be*
        *an indication that the problem you’re trying to solve is simply not an*
        *urgent one.*
        - *Put simply: if customers are not motivated to solve the problem, it’s*
        *likely that they don’t need your concept.*
    - *HOW LIKELY IS IT THAT YOU WOULD RECOMMEND THIS CONCEPT TO A FRIEND, FAMILY MEMBER, OR COLLEAGUE? (1: definitely would not, 5: definitely would)*
        - *WHY TO ASK THIS. When you ask a customer what they think of your*
        *concept, they may give you a positive response; but ask them to put*
        *their reputation on the line, and they become much more critical. We affectionately refer to this question as the “truth serum” question*
        *because it has a way of getting customers to tell you how they really*
        *feel.*
        - *WHAT TO LISTEN FOR. Listen for replies like “Well, before I could*
        *recommend it, I’d have to see how…” The things customers want to*
        *see before they would recommend your concept are the factors you’re*
        *interested in.*
        - *The value of this insight is that the customer is effectively telling you*
        *how they plan to “kick the tires” of your solution. If you were to release*
        *your concept today, these are the factors that customers would check*
        *to ensure your concept lives up to its promise.*
    - *HOW BELIEVABLE IS THIS CONCEPT AS A SOLUTION? (1: not very believable, 5: very believable)*
        - *WHY TO ASK THIS. The “believability” question will help you determine*
        *if your concept would be met with skepticism if it were released*
        *as a solution. At this point, you’re showing the customer an early, conceptual idea. You haven’t shown them any specific workflows or gone*
        *into depth about the specific implementation details.*
        - *WHAT TO LISTEN FOR. The customer might say, “I see what you’re trying*
        *to do, but I don’t think it can be done.” They may have opinions*
        *about where your concept might fail in the market. This is the type of*
        *sentiment you’re getting at with the believability score.*
        - *However, if the customer thinks your concept is believable and useful,*
        *it’s a good indication that you’ll be met by a market that’s ready to*
        *adopt your solution.*
    - *HOW DIFFERENT IS THIS CONCEPT FROM OTHER SOLUTIONS CURRENTLY AVAILABLE? (1: not at all different, 5: very different)*
        - *WHY TO ASK THIS. Ideally, as you evolve your concept, you’ll be keeping*
        *an eye on competitive solutions. The “uniqueness” question helps*
        *you identify if the customer finds your concept new and different from*
        *what the competition offers.*
        - *WHAT TO LISTEN FOR. This is also an opportunity for customers to*
        *offer any solutions you may be unaware of. Many customers find ways*
        *to solve their problems using their own tools or workarounds.*
        - *Listen for customers who are happy with their own solutions. It may be an*
        *indication that, while your concept may be offering something your*
        *competitors don’t, your customers are happily solving the problem on*
        *their own. In short, just because your concept is uniquely solving a*
        *problem, you shouldn’t assume your customers need it.*

## step 22

Debrief: At this point, you should be able to
answer the following questions about your concept:

- Would this concept solve a problem the customer is experiencing
today?
- Would customers try the concept today, if it were available?
- Would customers be willing to recommend the concept to a
friend or colleague?
- Does the customer find the concept unique and different
from what’s already available?

## step 23

*SELECT YOUR “MUST HAVE” CONCEPT BENEFITS.*
*1. Return to your evidence file where your categorized list of concept*
*benefits were captured.*
*2. Review your concept’s unique value proposition, benefits, and*
*limitations.*
*3. Select the “must have” benefits; these were the benefits that customers*
*found “most impactful.”*

## step 24

*Then, brainstorm and generate multiple feature ideas. These*
*are the features you believe your team could build to deliver each*
*benefit.*

## step 25

Ask the following questions about each feature:

- How much effort will it take to implement this feature?
- How much impact will this feature have on the customer?
- What’s the risk if we don’t implement this feature?

## step 26

Determine which quadrant on the Impact/Effort Matrix the feature
belongs in and hang it on the wall or board.

## step 27

- Example: The Heinz Ketchup Story
    
    *It was nearing the year 2000 and while everyone seemed to be worried*
    *about whether the world’s computers would be obliterated by the Y2K*
    *bug, Heinz, an American food processing company, was focused on*
    *an entirely different problem.*
    *People weren’t buying ketchup.*
    *To be clear, it wasn’t that people had completely stopped buying the*
    *tomato-based product, it was that they were starting to eat healthier*
    *and that meant eating fewer hamburgers, fries, and hot dogs, which in*
    *turn meant they had little need for ketchup.*
    *Heinz started the year with sales of ketchup hitting a plateau. It was,*
    *by far, their most successful product and they needed to act quickly to*
    *make sure that it stayed in homes for years to come.*
    *They considered many different ideas to refresh the public’s image of*
    *ketchup. One idea was to introduce a new line of ketchups, called EZ*
    *Squirt, that came in bold colors. The first color was green and was sold*
    *during the release of the movie Shrek. The company hoped that kids*
    *would eat the ketchup during the movie and develop a newfound love*
    *for the product.1*
    *Parents and kids had fun with the new ketchup as a novelty, but it*
    *didn’t really have lasting appeal. Heinz tried releasing new colors like*
    *blue and purple and even tried a “mystery color,” where customers*
    *didn’t know what color they were going to get. All the radically colored*
    *ketchups were met with lackluster sales.*
    
    *Heinz also turned to more functional ideas. They explored what was*
    *preventing customers from using ketchup and discovered a common*
    *problem: their customers didn’t like pouring it out of the bottle.*
    
    *Ketchup, as a thick, slow-pouring condiment, “plops” onto your food.*
    *In fact, Heinz ketchup is so slow to pour that the company had begun*
    *to celebrate it. In a 1987 commercial, television star Matt LeBlanc*
    *stands atop a building and strategically places a ketchup bottle on the*
    *edge of the roof. The ketchup begins to pour, and LeBlanc runs down*
    *several flights of stairs to a hot dog vendor on the street. He casually*
    *buys a hot dog and, at the very last minute, places it behind his back*
    *to catch the perfect pour of ketchup, falling neatly from the roof. A*
    *voice confidently announces, “Heinz. The best things come to those*
    *who wait.”2*
    *The ad was popular during the 80s and early 90s, but by 2000, people*
    *weren’t willing to wait for anything, even ketchup.*
    *The company tried squeeze bottles to improve speed, but the ketchup*
    *would stick inside the bottle, plop out unevenly, and make embarrassing*
    *sounds the company politely referred to as “bottle flatulence.”*
    *It seemed like they were out of ideas.*
    
    *Then Heinz discovered a man named Paul Brown. He was the owner*
    *of a small precision-molding shop in Midland, Michigan.3 Paul had*
    *a crazy dream. He wanted to build the perfect nozzle, which would*
    *allow products like shampoo, lotion, and, yes, even ketchup, to be*
    *poured evenly from a plastic bottle.*
    
    *What made Brown’s idea so unique was that the nozzle sat at the bottom*
    *of the bottle. Effectively, the bottle sat upside-down.*
    
    *Heinz knew it was the perfect solution to their problem.*
    
    *Through iteration, they created a dispensing nozzle that opened easily*
    *when the bottle was squeezed and closed quickly when the pressure*
    *stopped, resulting in a seamless and even pour. The nozzle and bottle*
    *were wide enough for the bottle to stand upside-down and leave*
    *ketchup at the nozzle, ready to pour. They even created a new bottle*
    *shape that made it easy to store in the side door of customers’ refrigerators*
    *(Figure 8-1).*
    
    *When Heinz began testing the new bottle design, customers loved it.*
    *It was released in 2002 and the upside-down bottle quickly became a*
    *hit, winning Heinz numerous product awards and driving ketchup*
    *sales up nearly 25 percent.*
    
    *This is not a story of a man who had an ingenious, upside-down idea.*
    *It’s a story of a company that knew that details mattered. They were*
    *willing to consider the entire experience of eating ketchup and refine*
    *a feature that had gone unnoticed.*
    *As product creators, we must pursue our product’s vision with the*
    *same level of care and craftsmanship.*
    *The Feature stage of the HPF is designed for tracking the implementation*
    *and design of the features that make up your concept.*
    
- pick the most optimal feature
- capture the criteria by which you will measure success of the feature. consider the following questions:
    - How will you know when a customer has successfully used
    the feature?
    - How will you determine if the feature is simple to use?
    - What would customers say if they are satisfied or enjoy the
    feature?
    - What type of behavior would customers display if they find
    your feature desirable?
    - How will you know when customers understand what they’re
    doing and why they’re doing it?

## step 28

- formulate a hypothesis for the feature
    - *We believe that [type of customers] will be successful solving*
    *[problem] using [feature] while doing [job-to-be-done].*
    - *We will know they were successful when we see [criteria].*

## step 29

define tasks

- *In the book Observing the User Experience: A Practitioner’s Guide to*
*User Research, authors Elizabeth Goodman, Mike Kuniavsky, and*
*Andrea Moed write that a good task should be Reasonable, Achievable, Specific, and Sequential*
    - Reasonable
        - *Something you could reasonably expect a customer to do in everyday*
        *situations.*
        - *Don’t test outliers or situations that rarely occur. You may be*
        *tempted to put your feature “through the ringer,” but you don’t*
        *want to optimize your design for extreme cases. Plus, it’ll frustrate*
        *your customer if you’re giving them a task that is too hard*
        *to complete.*
    - Achievable
        - *“Solvable”—that is, they can be completed by the customer.*
        - *You should know what exact steps are needed to complete the task.*
        *If you’ve written down your Feature hypotheses, you should be*
        *anticipating what the customer will encounter as they navigate*
        *the task.*
    - Specific
        - *Detailed and descriptive. Avoid tasks that are vague and left to the*
        *customer’s interpretation.*
        - *The task should be specific and have an understood outcome. You*
        *shouldn’t ask, “How would you search for a service provider on*
        *our website?” Instead, you should say, “I’d like you to find a carpet*
        *cleaning service, located five miles from your location.”*
    - Sequential
        - *he tasks should walk a customer through an entire workflow in*
        *order. Avoid “jumping around” doing tasks that are unassociated*
        *with each other.*
        - *Create a usability study that has customers progressing through*
        *a realistic sequence of events. Avoid having them bounce around*
        *from experience to experience. It may create unnecessary confusion*
        *and affect the results of your study.*

## step 30

build a prototpye

Then, Prototype. *You’ll need a way for customers to interact with your feature to complete the tasks you’ve given them. One way to achieve this is by creating*
*a prototype. A sketch, a wireframe, or an interactive prototype*

## step 31

interview customers part 1:

*Before you introduce the feature, ask the following questions.*

- validate problem, job to be done, etc

## step 32

show them your prototype

- tips
    - *It’s important that customers tell you what they think your feature does; they shouldn’t be listening to you*
    *explain it to them.*
    - *It’s okay to let them struggle. Give them time to figure it out and*
    *encourage them to talk aloud, explaining what they’re looking at and*
    *how they plan to interact with it. If you rush in to help, you’ll miss key*
    *opportunities to learn how your customer will process and navigate*
    *your feature.*
    - *If customers are having a hard time navigating your usability study, you might consider higher-fidelity compositions, smaller scenarios, is it the right customer, is it the right problem?*
        - *Higher-fidelity compositions*
            - *Your screen compositions might be too vague, making it difficult*
            *for customers to determine what your feature does.*
        - Smaller scenarios
            - *Your feature may be too wide sweeping. It may be best to break up*
            *the experiences into smaller scenarios that customers can wrap*
            *their heads around.*
        - The right customer
            - *It’s possible that you need to revisit the Customer stage and ensure*
            *you’re targeting the right customer. Perhaps the customers you’re*
            *talking to don’t have the knowledge and experience to navigate*
            *the scenarios you’re testing. Perhaps the customer you’re targeting*
            *doesn’t exist.*
        - *The right problem*
            - *You may have to return to the Problem stage to determine whether*
            *you’re solving the right problem. If you’re finding that customers*
            *are having difficulty understanding the problem you’re trying to*
            *solve, there’s a high probability that they simply don’t have that*
            *problem.*

## step 33

interview customers part 2:

*Use the following questions, or a modified version, after you’ve conducted*
*the usability test.*

- questions that validate [feature]
    
    *• Would using this [feature] be useful in your job?*
    *• Would using this [feature] make you more productive?*
    *• Assuming this [feature] were available, would you use it on a regular*
    *basis?*
    *• Do you think this [feature] would be easy to learn?*
    *• Would you be satisfied using this [feature]?*
    *• Would you recommend this [feature] to a friend or colleague?*
    
- questions that validate usability
    
    *1. It is simple to use.*
    *(Scale: “Strongly Disagree” (1) – (2) – (3) – (4) – (5) – (6) – (7) “Strongly Agree”)*
    *2. It is useful.*
    *(Scale: “Strongly Disagree” (1) – (2) – (3) – (4) – (5) – (6) – (7) “Strongly Agree”)*
    *3. It is fun to use.*
    *(Scale: “Strongly Disagree” (1) – (2) – (3) – (4) – (5) – (6) – (7) “Strongly Agree”)*
    *4. It does everything I would expect it to do.*
    *(Scale: “Strongly Disagree” (1) – (2) – (3) – (4) – (5) – (6) – (7) “Strongly Agree”)*
    *5. I learned to use it quickly.*
    *(Scale: “Strongly Disagree” (1) – (2) – (3) – (4) – (5) – (6) – (7) “Strongly Agree”)*
    *6. It would help me be more effective.*
    *(Scale: “Strongly Disagree” (1) – (2) – (3) – (4) – (5) – (6) – (7) “Strongly Agree”)*
    

## step 34

debrief

*Dr. Arnie Lund, Senior Research Manager at Amazon, measures*
*usability with a USE questionnaire, which stands for Usefulness,*
*Satisfaction, and Ease of use.*

- *These dimensions help us determine whether a feature was successful*
*by asking ourselves:*
    
    *• Were customers able to complete the task?*
    *• Did they encounter any unexpected errors? How did they handle*
    *it?*
    *• Throughout the task, did they understand what they were doing*
    *and why they were doing it?*
    *• Were they efficient and accurate, or did they labor and become*
    *confused?*
    *• Did they appear confident and satisfied?*
    *• Did they need additional help and were they able to find it quickly?*